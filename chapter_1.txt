Problem set summary: The most enjoyable was 12, in particular proving Rice's Theorem. Fully specifying at least one TM was useful (Problem 1), but I didn't see the need to do more than that. Problem 5, about the oblivious TM, was where I felt I was building up a lot of the mental framework around this material. It took me the longest to solve. Problem 13 is obviously important, and it was worthwhile to work through, even though it was underspecified and I'm not sure my answers are formally correct. The rest of the problems, while often important to have thought of, were mostly easier and I didn't go into full detail.

1. See c1.py for addition, and the outline for multiplication.

2-4. Shrink alphabet, reduce tapes, and unidirectional tape: skipping explicit TM construction.

5. 
We can construct an oblivious TM M' such that L(M)=L(M') using a technique similar to that in the proof of Claim 1.6. 

Observe that (1) after n steps, M's tape heads will all be in the position range [-n, n], and (2) since M runs in time O(T(n)), there exists some constant k such that for every input n, M runs n fewer than k*T(n) steps. 

First, add two additional work tapes T_1 and T_2. The first thing M' does is count the length of the input and write it to T_1. Next, write k*T(n) to T_2. Since T is time-constructible, and we have the value of 'n' on T_1, this takes time at most T(n). 

Next, we simulate the execute of M in an oblivious way. We simulate each step i of M's execution as follows:
- Start every head t position -i. Move it right to position +i, finding the tape-head-location marker along the way (See Claim 1.6). We note the tapes's movement, writes, and state transition and then return to -(i+1) to begin the next step. If a tape's head is to move right, do so on the right pass, otherwise remember and when we see the marker on the way back, move it at that time. The write and state change can be made on the first pass. 
- Simultaneously, decrement the value on T_2.

When T_2 is 0, halt.

The proof of language equality is essentially the same as in Claim 1.6, and obliviousness is apparent. Waiting k*T(n) simulated steps to halt guarantees that all machines of this input length would have halted by then.

Time anlaysis:
a. Writing T_1, incrementing one-by-one, takes time n*log(n). (For each symbol in the input, we may have to manipulate up to log(n) inputs of the length-so-far's binary representation to increment the value.)
b. Writing T_2 takes time T(n), by the definition of time-constructible
c. Each simulation step, the tapes move up to O(T(n)) steps. Keeping track of -i and i can be done on another tape that simply counts in unary, with the head moving across it to count out the correct distance.
d. Decrementing T_2 takes O(log(k*T(n))) = O(log(T(n))) steps
e. Multiplying c+d by the O(T(n)) "simulated steps" gets us O(T(n))*O(T(n) + log(T(n))) = O(T(n)*T(n) + log(T(n))*T(n)), and since and log(T(n)) < T(n), this simulation runs in O(T(n)**2)

It remains to show that this simulation can be done in as few as 2 tapes. To do this, we interleave all tapes other than the input tape in the standard way. 
- Writing T_1 is only a constant factor slower.
- Similarly with writing T_2, since these are performed sequentially with no other non-input tapes active.
- Each simulation step is also only a constant-factor slower, since we can run over all the interleaved tapes at once, and the T_2 decrement is performed sequentially afterward. 

6. Use a similar construction to 5 above, with T_1, T_2, and decrementing T_2 for each step of the simulation. However, we (a) forget about doing it only 2 tapes, and (b) simulate each step in a different way.
Instead of simulating each head by marking and moving obliviously, we adapt the construction from the proof of Theorem 1.9. Every 2**i steps, we perform a left shift at index i followed by a right shift at index i. ??

7. Map the plane to the linear tape by using a spiral. Since each 2-D move at worst moves to an adjacent turn of the spiral, and the circumfurence of the turn we're on at at step n is O(n), we have to move at most n steps to get to the head's next location. We can use a scratch tape to record the destination address and compare against it (O(log(n))). Thus O(T(n)*n).

8. First copy i to a scratch tape. Then, with the input head positioned at the start of x, decrement i until it's 0. This takes i*log(i) steps. At each one, move the input head right. Output the final result, or 0 if x runs out before we've reached 0. That's polynomial in the input time, so it's in P.

9. We store all of the "RAM" on a sequential tape. In the execution of our original machine M, it can write to the RAM at most O(T(n)) times. Therefore, our simulated RAM in M' contains at most O(T(n)) elements. We store these elements as (position, value) pairs separated by a special marker. In M', when we move to state q_access, move the simulated-RAM tape head to the start position, then move it right until the (position) matches i, and then take the appropriate action on the address tape with the adjacent value. Since the simulated-RAM tape is of length at most T(n), this takes at most T(n) time, being a linear read. Therefore, each step of our modified M' takes time at most T(n), giving a resultant simulation time of T(n)**2.

10. We assume the program starts at the first line and i is initially 0. This programming language maps quite directly to a Turing Machine. Assign a state to each line of the program. The variable i is the position of the tape head. Every label could do one of two things, depending on whether the tape matches \sigma: continue in that block, or (assuming) skip to the next label. This is represented in the TM's transition table as two obvious transitions, to either the next line or the next label's line, depending on the input. Commands that "Set" a value correspond to the TM's output, and a "Stay" move. The "Goto" command corresponds to a state transition (to the label's line's state) with no output. The increment and decrement commands corresponding to moving the tape head left and right, again without output. Finally, the "Output" command is equivalent to writing on the TM's output tape and halting. In none of these cases does the TM require more than one step to execute a line of the program, so if the program runs in T(n) then the TM does too.

11. See c1.py.

12. 
a. Let S be the set of total functions, i.e. all functions computable by a T_M that always halts. Then f_S is the Boolean function that on input \alpha outputs 1 iff M_\alpha computers a function in S. If HALT were computable, f_S would be computable: f_S(x) is 1 if M_x always halts, or 0 if it doesn't. But f_S is not computable -- by Rice's Theorem -- so HALT is not computable.
b. 
    Assume, for sake of contradiction, that there is some non-trivial set S of partial functions that induces a computable function f_S. Then, there is some machine M_S that computes f_S. In other words, given a machine M, we M_S(M) determines whether M computes a partial function in S. 

    Given a TM M, let Bind(M, i) be the machine that ignores its input and simulates M on i
    #Given a TM M, let Wrap(M, i, action) be the machine that first checks if it's input equals i. If it is, it performs `action`, which is either a finite string, meaning print that string and halt, or LOOP, meaning enter an infinite loop.

    Give any machine M_orig and input i, we can determine, using M_S, whether the machine M_orig halts on input i as follows:
    0. Let M = Bind(M_orig, i)
    1. let s1 = M_S(M)
    2. Find the first machine M' such that M_S(M') != s1. Such a machine exists, because S is non-trivial, and we can find it by running M_S on every string until we find one.
    3. Let s2 = M_S(M')
    4. For each binary string x, in lexicographic order:
        a. Let M_x be the TM that simulates M' if it's input is less than or equal to x, and simulates M otherwise
        b. If M_S(M_x) != s1, BREAK (remembering the values x and M_x)
        (This procedure must terminate because s1 != s2.)
    5. Let Loop be the machine that loops on every input
    6. Let sL = M_S(Loop)
    7. Since s1 != s2, one of them must be different than sL. 
    8. If s1 != sL: return FALSE (Since M behaves the same on every input (it ignores its input), then behaving differently than sL means it halts on every input.)
# So s1 == sL != s2
    9. Let M_x2 be the machine that operates like M_x, except on input x, where it behaves as follows: Simulate M' on x, and if it halts, simulate M on x
    10. Let sx2 = M_S(M_x2)
    11. If sx2 == s2: return TRUE. M_x2 did not behave like M on x. If M' halted on x, M_x2 would have behaved like M on x, by definition. Therefore, it looped forever, meaning M does not loop on X, meaning it halts.
# So sx2 == s1 == sL != s2
    12. Let O=M'(x). We know by the explanation in step 11 that M' must halt on x.
    13. Let M_O be the machine that simulates M, except on x where it waits for M to halt and then prints O.
    14. Return M_S(M_O) != s1
        If M_S(M_O) == s1, then we know that M_O behaves like M on x, meaning it can't halt, meaning M never halts, so return False.
        if M_S(M_O) == s2, then we know that M_O's simulation of M halted on x, so return True.

    By the algorithm above, we have used the computability of some arbitrary f_S to solve the halting problem, which is impossible. Therefore there is no computable f_S. QED.

13
a. 
DIVIDES(x, y) = \exists k : y = x * k
PRIME(y) = \forall x (x=1) \lor (x=y) \lor \lnot DIVIDES(x, y)
CUBE(x) = x*x*x # macros?
IN_RANGE(i, x) = (x > CUBE(i + C)) \land (x < CUBE(i + C + 1))
P(i) = x: IN_RANGE(i, x) \land PRIME(x) \land ( \forall y: \lnot PRIME(y) \lor \lnot IN_RANGE(i, y) \lor (y > x) \lor y = x) # Is this allowed?
BIT(n,i) = DIVIDES(P(i), n)

b. COMPARE(n, m, i, j) = BIT(n, i) \land BIT(m, j)
c. Assume it's one-directional as well. Store (state name, head position index, list of tape entries) packed and encoded as in the solution to Problem 11.
d. INIT_(M,x)(n) = \forall x: COMPARE(n, <the pre-computed TM state encoding>, x, x)
e. HALT_M(n) = an expression that gets the bit on the tape under the head, and the state, and has a precomputed set of all (state, input) pairs that lead to HALT and compares the pair encoded by n to that set
f. NEXT(n, m) is similar to above, except it compares the pair of tapes on the tape movement to the encoded transition table
g. VALID_M(m, t) = \forall x: (x > t) \lor NEXT(m[x], m[x+1])
h. HALT_(M,x)(t) = \exists m : VALID_M(m, t) \land (m[0] = INIT_(M,x)(x)) \land HALT_M(m[t]) # assuming for simplicity that HALT transitions to HALT
i. As we can see above, HALT(x, i) can be encoded as a number-theoretic statement. Therefore, number-theoretic statements are uncomputable.

14. High-level poly-time algorithms without proof.
a. Use a union-find data structure. Traverse the adjacency list, and union all pairs of vertices that are adjacent. At the end, return true iff there is exactly one set in the data structure.
b. For each triple of vertices, check whether all three sides of the triangle are in the adjacency list. If they are, return false. Otherwise, at the end, return true.
c. 
While any vertex is not colored:
    Create a queue
    Pick an uncolored vertex and add it into the queue
    While the queue is not empty:
        Get the vertex from the queue
        Mark this vertex as "processed"
        If it's uncolored, assign it the color red or blue arbitrarily
        For each of its neighbors:
            If it's the same color as this vertex, return false
            If it's uncolored, assign it the opposite color of this vertex
            If it isn't "processed", add it to the queue
Return true
d. First, make sure it's connected with the algorithm from (a). Then:
Create a queue
Pick any starting vertex and add it to the queue
While the queue is nonempty:
    get the first vertex from the queue
    mark it as "processed"
    for each of its edges:
        if the edge is "processed":
            do nothing
        otherwise:
            if the adjacent vertex is "processed": return false
            else: 
                mark the edge as processed
                append the adjacent vertex to the queue

15. 
a. The binary-coded representation in base b>2 uses a constant multiple more space compared to the binary reprentation. It can be manipulated as such, or translated back and forth in polynomial time.
b. Given a number n in unary, we can check if a unary number x divides it as follows: repeatedly write x to a work tape, while moving the tape head that holds n across n. If the latter reaches the end of n at the same time that and instance of "x" finishes writing, return it is divisible, otherwise it is not. This takes time linear in n. To try all possibilities between l and k requires k-l tries, which is linear in the size of k+l. So UNARYFACTORING can be solved in O(n**2) which is in P.


